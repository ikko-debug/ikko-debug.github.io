<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="Ikko">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    
        
        
        
            <link rel="preconnect" href="https://registry.npmmirror.com" crossorigin>
        
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://ikko-debug.github.io/2023/04/19/爬虫/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
    
    
        
        <meta name="description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:type" content="article">
<meta property="og:title" content="爬虫">
<meta property="og:url" content="http://ikko-debug.github.io/2023/04/19/%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="IKKO">
<meta property="og:description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://ikko-debug.github.io/images/redefine-og.webp">
<meta property="article:published_time" content="2023-04-19T04:58:02.000Z">
<meta property="article:modified_time" content="2023-05-22T06:16:01.623Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://ikko-debug.github.io/images/redefine-og.webp">
    
    
        <!-- Google tag (gtag.js) -->
        <script src="https://www.googletagmanager.com/gtag/js?id=G-P5152X2PGJ"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-P5152X2PGJ');
        </script>
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/idea.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/idea.svg">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/idea.svg">
    <!--- Page Info-->
    
    <title>
        
            爬虫 | IKKO
        
    </title>

    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fonts/Chillax/chillax.css">

    <!--- Inject Part-->
    

    
<link rel="stylesheet" href="/css/style.css">


    
        <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/css/build/tailwind.css">
    

    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fonts/GeistMono/geist-mono.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fonts/Geist/geist.css">
    <!--- Font Part-->
    
    
    
    
    
    

    <script id="hexo-configurations">
    window.config = {"hostname":"ikko-debug.github.io","root":"/","language":"en","path":"search.xml"};
    window.theme = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true,"delete_mask":false,"title_alignment":"left","headings_top_spacing":{"h1":"3.2rem","h2":"2.4rem","h3":"1.9rem","h4":"1.6rem","h5":"1.4rem","h6":"1.3rem"}},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":true,"list":[""]},"code_block":{"copy":true,"style":"mac","highlight_theme":{"light":"github","dark":"vs2015"},"font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":{"enable":true,"default":"cc_by_nc_sa"},"lazyload":true,"pangu_js":false,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null,"default_mode":"dark"},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null},"title":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"website_counter":{"url":"https://cn.vercount.one/js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"preloader":{"enable":false,"custom_message":null},"open_graph":{"enable":true,"image":"/images/redefine-og.webp","description":"Hexo Theme Redefine, Redefine Your Hexo Journey."},"google_analytics":{"enable":true,"id":"G-P5152X2PGJ"}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/light.jpg","dark":"/images/dark.jpg"},"title":"若有恒，何必三更眠五更起 最无益，只怕一日曝十日寒","subtitle":{"text":[],"hitokoto":{"enable":false,"show_author":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"1.5rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":false,"style":"default","links":{"github":"https://github.com/ikko-debug","instagram":null,"zhihu":null,"twitter":null,"email":null},"qrs":{"weixin":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null,"lrc":null}]},"mermaid":{"enable":false,"version":"11.4.1"}},"version":"2.8.2","navbar":{"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"width":{"home":"1200px","pages":"1000px"},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"FriendLinks":{"icon":"fa-solid fa-link","submenus":{"yebao":"https://danmoliuhen.github.io/","wu-22":"https://wu-22.github.io/","jjb":"https://byjiangjb.github.io/"}},"album":{"icon":"fa-solid fa-image","path":"/masonry/"}},"search":{"enable":true,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":null,"show_on_mobile":true,"links":null},"article_date_format":"auto","excerpt_length":200,"categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2022/8/17 11:45:14"};
    window.lang_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    window.data = {"masonry":true};
  </script>
    
    <!--- Fontawesome Part-->
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fontawesome/fontawesome.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fontawesome/brands.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fontawesome/solid.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fontawesome/regular.min.css">
    
    
    
    
<meta name="generator" content="Hexo 6.3.0"></head>



<body>
	<div class="progress-bar-container">
	

	
	<span class="pjax-progress-bar"></span>
	<!--        <span class="swup-progress-icon">-->
	<!--            <i class="fa-solid fa-circle-notch fa-spin"></i>-->
	<!--        </span>-->
	
</div>

<main class="page-container" id="swup">

	

	<div class="main-content-container flex flex-col justify-between min-h-dvh">
		<div class="main-content-header">
			<header class="navbar-container px-6 md:px-12">
    <div class="navbar-content transition-navbar ">
        <div class="left">
            
                <a class="logo-image h-8 w-8 sm:w-10 sm:h-10 mr-3" href="/">
                    <img src="/images/idea.svg" class="w-full h-full rounded-sm">
                </a>
            
            <a class="logo-title" href="/">
                
                IKKO
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/"
                                        >
                                    <i class="fa-regular fa-house fa-fw"></i>
                                    HOME
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/archives"
                                        >
                                    <i class="fa-regular fa-archive fa-fw"></i>
                                    ARCHIVES
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown"
                                   href="#"
                                        onClick=&#34;return false;&#34;>
                                    <i class="fa-solid fa-link fa-fw"></i>
                                    FRIENDLINKS
                                    <i class="fa-solid fa-chevron-down fa-fw"></i>
                                </a>

                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                        
                                            <li>
                                                <a target="_blank" rel="noopener" href="https://danmoliuhen.github.io/">
                                                    YEBAO
                                                </a>
                                            </li>
                                        
                                            <li>
                                                <a target="_blank" rel="noopener" href="https://wu-22.github.io/">
                                                    WU-22
                                                </a>
                                            </li>
                                        
                                            <li>
                                                <a target="_blank" rel="noopener" href="https://byjiangjb.github.io/">
                                                    JJB
                                                </a>
                                            </li>
                                        
                                    </ul>
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/masonry/"
                                        >
                                    <i class="fa-solid fa-image fa-fw"></i>
                                    ALBUM
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                    
                        <li class="navbar-item search search-popup-trigger">
                            <i class="fa-solid fa-magnifying-glass"></i>
                        </li>
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i>
                    </div>
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile sheet -->
    <div class="navbar-drawer h-dvh w-full absolute top-0 left-0 bg-background-color flex flex-col justify-between">
        <ul class="drawer-navbar-list flex flex-col px-4 justify-center items-start">
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/"
                        >
                            <span>
                                HOME
                            </span>
                            
                                <i class="fa-regular fa-house fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/archives"
                        >
                            <span>
                                ARCHIVES
                            </span>
                            
                                <i class="fa-regular fa-archive fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item-sub text-base my-1.5 flex flex-col w-full">
                        
                        <div class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary cursor-pointer text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                             navbar-data-toggle="submenu-FriendLinks"
                        >
                            <span>
                                FRIENDLINKS
                            </span>
                            
                                <i class="fa-solid fa-chevron-right fa-sm fa-fw transition-all"></i>
                            
                        </div>
                        

                        
                            <div class="flex-col items-start px-2 py-2 hidden" data-target="submenu-FriendLinks">
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           target="_blank" rel="noopener" href="https://danmoliuhen.github.io/">YEBAO</a>
                                    </div>
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           target="_blank" rel="noopener" href="https://wu-22.github.io/">WU-22</a>
                                    </div>
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           target="_blank" rel="noopener" href="https://byjiangjb.github.io/">JJB</a>
                                    </div>
                                
                            </div>
                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/masonry/"
                        >
                            <span>
                                ALBUM
                            </span>
                            
                                <i class="fa-solid fa-image fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            

            
            
        </ul>

        <div class="statistics flex justify-around my-2.5">
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/tags">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">6</div>
        <div class="label text-third-text-color text-sm">Tags</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/categories">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">0</div>
        <div class="label text-third-text-color text-sm">Categories</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/archives">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">23</div>
        <div class="label text-third-text-color text-sm">Posts</div>
    </a>
</div>
    </div>

    <div class="window-mask"></div>

</header>


		</div>

		<div class="main-content-body transition-fade-up">
			

			<div class="main-content">
				<div class="post-page-container flex relative justify-between box-border w-full h-full">
	<div class="article-content-container">

		<div class="article-title relative w-full">
			
			<div class="w-full flex items-center pt-6 justify-start">
				<h1 class="article-title-regular text-second-text-color tracking-tight text-4xl md:text-6xl font-semibold px-2 sm:px-6 md:px-8 py-3">爬虫</h1>
			</div>
			
		</div>

		
		<div class="article-header flex flex-row gap-2 items-center px-2 sm:px-6 md:px-8">
			<div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]">
				<img src="/images/56D9D2F8A1A04F1D59D48CAD0011E450.jpg">
			</div>
			<div class="info flex flex-col justify-between">
				<div class="author flex items-center">
					<span class="name text-default-text-color text-lg font-semibold">Ikko</span>
					
					<span class="author-label ml-1.5 text-xs px-2 py-0.5 rounded-small text-third-text-color border border-shadow-color-1">Lv3</span>
					
				</div>
				<div class="meta-info">
					<div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2023-04-19 12:58:02</span>
        <span class="mobile">2023-04-19 12:58:02</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2023-05-22 14:16:01</span>
            <span class="mobile">2023-05-22 14:16:01</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fa-regular fa-typewriter"></i>&nbsp;<span>3.6k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fa-regular fa-clock"></i>&nbsp;<span>17 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

				</div>
			</div>
		</div>
		

		


		<div class="article-content markdown-body px-2 sm:px-6 md:px-8 pb-8">
			<h2 id="初始代码"><a href="#初始代码" class="headerlink" title="初始代码"></a>初始代码</h2><p>copyright from <a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/INTEGRATOR_37/article/details/113386649" >https://blog.csdn.net/INTEGRATOR_37/article/details/113386649<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.gov.cn/zhengce/zuixin.htm&#x27;</span></span><br><span class="line">UA = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36&#x27;</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;User_Agent&#x27;</span>: UA&#125;</span><br><span class="line"></span><br><span class="line">r = requests.get(url, headers=headers)</span><br><span class="line">r.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(r.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">attrs = &#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;date&#x27;</span>&#125;</span><br><span class="line">links = soup.find_all(href=re.<span class="built_in">compile</span>(<span class="string">&#x27;content&#x27;</span>))</span><br><span class="line">dates = soup.find_all(name=<span class="string">&#x27;span&#x27;</span>, attrs=attrs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get titles and links</span></span><br><span class="line">titles = []</span><br><span class="line">urls = []</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">    titles.append(<span class="built_in">str</span>(link.string))</span><br><span class="line">    url = link.get(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">    urls.append(<span class="built_in">str</span>(url))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get days</span></span><br><span class="line">days = []</span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;(\d+)\-(\d+)\-(\d+)&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> date <span class="keyword">in</span> dates:</span><br><span class="line">    s = date.string</span><br><span class="line">    day = re.search(pattern, s)</span><br><span class="line">    days.append(<span class="built_in">str</span>(day.group()))</span><br><span class="line"></span><br><span class="line">data = &#123;<span class="string">&#x27;date&#x27;</span>: days,</span><br><span class="line">        <span class="string">&#x27;title&#x27;</span>: titles,</span><br><span class="line">        <span class="string">&#x27;url&#x27;</span>: urls&#125;</span><br><span class="line">frame = DataFrame(data)</span><br><span class="line">frame.to_csv(<span class="string">&#x27;test.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></div>
<h2 id="个人理解"><a href="#个人理解" class="headerlink" title="个人理解"></a>个人理解</h2><p>上面这段代码主要的目的是抓取中国政府网（<a class="link"   target="_blank" rel="noopener" href="http://www.gov.cn)中最新的法规政策,并将其日期、标题和链接保存到csv文件中./" >www.gov.cn）中最新的法规政策，并将其日期、标题和链接保存到CSV文件中。<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li><code>import requests</code>: 引入requests库，用于网络请求操作。</li>
<li><code>import re</code>: 引入re库，用于正则表达式匹配。</li>
<li><code>from bs4 import BeautifulSoup</code>: 引入BeautifulSoup库，用于解析HTML页面。</li>
<li><code>from pandas import DataFrame</code>: 引入DataFrame库，用于构建数据表格。</li>
</ul>
<p>接下来是变量定义：</p>
<ul>
<li><code>url = &#39;http://www.gov.cn/zhengce/zuixin.htm&#39;</code>：指定要爬取数据的网站URL。</li>
<li><code>UA = &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36&#39;</code>：设置User-Agent，模拟浏览器进行访问。</li>
<li><code>headers = &#123;&#39;User_Agent&#39;: UA&#125;</code>: 设置请求头部信息，包括User-Agent。</li>
<li><code>r = requests.get(url, headers=headers)</code>：发送HTTP GET请求获取网站页面源码。</li>
<li><code>r.encoding = &#39;utf-8&#39;</code>：设置网页内容的编码格式为UTF-8。</li>
<li><code>soup = BeautifulSoup(r.text, &#39;lxml&#39;)</code>：使用BeautifulSoup库解析HTML页面。</li>
<li><code>attrs = &#123;&#39;class&#39;: &#39;date&#39;&#125;</code>：设定属性字典{‘class’: ‘date’}，以查找所有class为’date’的span标签。</li>
<li><code>links = soup.find_all(href=re.compile(&#39;content&#39;))</code>：使用正则表达式查找href属性中包含’content’字符串的所有a标签。</li>
<li><code>dates = soup.find_all(name=&#39;span&#39;, attrs=attrs)</code>：查找所有class为’date’的span标签，并通过attrs参数和name参数指定进一步的筛选条件。</li>
</ul>
<p>接下来，代码获取标题、链接和日期数据：</p>
<ul>
<li>使用for循环遍历所有查找到的links元素，将其中的标题保存到变量titles列表中，将链接地址存储到urls列表中。</li>
<li>使用正则表达式从日期的字符串中提取出日期信息，并将其追加到days列表中。</li>
</ul>
<p>最后，该程序创建了一个数据字典data，并使用DataFrame类构建了一个数据表格frame。然后，将这个表格以CSV格式写入test.csv文件中，其中index&#x3D;False指定不要写入索引值（即第一列）到文件中。<br>爬出数据是这样的：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">date,title,url</span><br><span class="line">2023-04-18,中共中央印发《中央党内法规制定工作规划纲要（2023－2027年）》,/zhengce/2023-04/18/content_5752088.htm</span><br><span class="line">2023-04-18,国务院办公厅关于调整第19届亚运会和第4届亚残运会工作领导小组组成人员等有关事项的通知,http://www.gov.cn/zhengce/content/2023-04/18/content_5752017.htm</span><br><span class="line">2023-04-14,国务院办公厅关于上市公司独立董事制度改革的意见,http://www.gov.cn/zhengce/content/2023-04/14/content_5751463.htm</span><br><span class="line">2023-04-12,征兵工作条例,http://www.gov.cn/zhengce/content/2023-04/12/content_5750986.htm</span><br><span class="line">2023-04-10,中共中央发出关于学习《习近平著作选读》第一卷、第二卷的通知,/zhengce/2023-04/10/content_5750697.htm</span><br><span class="line">2023-04-07,国务院办公厅关于成立第五次全国经济普查领导小组的通知,http://www.gov.cn/zhengce/content/2023-04/07/content_5750375.htm</span><br></pre></td></tr></table></figure></div>
<h2 id="代码修改"><a href="#代码修改" class="headerlink" title="代码修改"></a>代码修改</h2><h3 id="url修改"><a href="#url修改" class="headerlink" title="url修改"></a>url修改</h3><p>首先可以看到爬取的url是不规范的，有的是绝对url，有的是相对url，这样就需要对url进行处理，使其都是绝对url。对于不规范的URL，我们可以使用Python中的urllib.parse.urljoin()函数将相对URL转化为绝对URL。该函数可以将基础URL和相对URL合并成一个完整的URL，并返回结果。<br>通过调用urljoin()函数，将上述示例中的URL处理为绝对URL：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin</span><br><span class="line"></span><br><span class="line">base_url = <span class="string">&#x27;http://www.gov.cn/&#x27;</span></span><br><span class="line">data = [</span><br><span class="line">    (<span class="string">&#x27;2023-04-18&#x27;</span>, <span class="string">&#x27;中共中央印发《中央党内法规制定工作规划纲要（2023－2027年）》&#x27;</span>, <span class="string">&#x27;/zhengce/2023-04/18/content_5752088.htm&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;2023-04-18&#x27;</span>, <span class="string">&#x27;国务院办公厅关于调整第19届亚运会和第4届亚残运会工作领导小组组成人员等有关事项的通知&#x27;</span>, <span class="string">&#x27;http://www.gov.cn/zhengce/content/2023-04/18/content_5752017.htm&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;2023-04-14&#x27;</span>, <span class="string">&#x27;国务院办公厅关于上市公司独立董事制度改革的意见&#x27;</span>, <span class="string">&#x27;http://www.gov.cn/zhengce/content/2023-04/14/content_5751463.htm&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;2023-04-12&#x27;</span>, <span class="string">&#x27;征兵工作条例&#x27;</span>, <span class="string">&#x27;http://www.gov.cn/zhengce/content/2023-04/12/content_5750986.htm&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;2023-04-10&#x27;</span>, <span class="string">&#x27;中共中央发出关于学习《习近平著作选读》第一卷、第二卷的通知&#x27;</span>, <span class="string">&#x27;/zhengce/2023-04/10/content_5750697.htm&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;2023-04-07&#x27;</span>, <span class="string">&#x27;国务院办公厅关于成立第五次全国经济普查领导小组的通知&#x27;</span>, <span class="string">&#x27;http://www.gov.cn/zhengce/content/2023-04/07/content_5750375.htm&#x27;</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> date, title, url <span class="keyword">in</span> data:</span><br><span class="line">    full_url = urljoin(base_url, url)</span><br><span class="line">    <span class="built_in">print</span>(date, title, full_url)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>对于相对URL，urljoin()函数会自动补全为绝对URL，而对于绝对URL，则不会进行任何更改。</p>
<h3 id="修改成功后发现，绝对url和相对url对应的页面结构是不同的"><a href="#修改成功后发现，绝对url和相对url对应的页面结构是不同的" class="headerlink" title="修改成功后发现，绝对url和相对url对应的页面结构是不同的"></a>修改成功后发现，绝对url和相对url对应的页面结构是不同的</h3><h4 id="添加判断url为相对url还是绝对url"><a href="#添加判断url为相对url还是绝对url" class="headerlink" title="添加判断url为相对url还是绝对url"></a>添加判断url为相对url还是绝对url</h4><p>可以使用Python的urllib.parse.urlparse()函数将URL解析成6个部分（scheme，netloc，path，params，query和fragment），然后检查其中是否包含netloc字段，如果netloc为空，就是相对URL，否则就是绝对URL。</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_relative_url</span>(<span class="params">url</span>):</span><br><span class="line">    parsed_url = urlparse(url)</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">not</span> <span class="built_in">bool</span>(parsed_url.netloc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line"><span class="built_in">print</span>(is_relative_url(<span class="string">&#x27;/zhengce/2023-04/18/content_5752088.htm&#x27;</span>))     <span class="comment"># True</span></span><br><span class="line"><span class="built_in">print</span>(is_relative_url(<span class="string">&#x27;http://www.gov.cn/zhengce/content/2023-04/14/content_5751463.htm&#x27;</span>))     <span class="comment"># False</span></span><br></pre></td></tr></table></figure></div>
<h4 id="先处理相对url"><a href="#先处理相对url" class="headerlink" title="先处理相对url"></a>先处理相对url</h4><p>相对url有四个字段：标题，时间，来源，正文</p>
<h5 id="提取标题"><a href="#提取标题" class="headerlink" title="提取标题"></a>提取标题</h5><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line">url = <span class="string">&#x27;http://www.gov.cn/zhengce/2023-04/18/content_5752088.htm&#x27;</span></span><br><span class="line">UA = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36&#x27;</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;User_Agent&#x27;</span>: UA&#125;</span><br><span class="line"></span><br><span class="line">r = requests.get(url, headers=headers)</span><br><span class="line">r.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(r.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">title_element = soup.find(<span class="string">&#x27;h1&#x27;</span>)</span><br><span class="line">title = title_element.get_text().strip()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(title)  <span class="comment"># 输出 &quot;中共中央印发《中央党内法规制定工作规划纲要（2023－2027年）》&quot;</span></span><br></pre></td></tr></table></figure></div>
<h5 id="提取发布时间和来源"><a href="#提取发布时间和来源" class="headerlink" title="提取发布时间和来源"></a>提取发布时间和来源</h5><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用class属性查找包含发布时间和来源的div元素</span></span><br><span class="line">pages_date = soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;pages-date&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取发布时间和来源的文本内容</span></span><br><span class="line">publish_time = pages_date.contents[<span class="number">0</span>].strip()</span><br><span class="line"><span class="comment"># 将日期字符串转换为datetime类型的数据</span></span><br><span class="line">publish_time = datetime.strptime(publish_time, <span class="string">&#x27;%Y-%m-%d %H:%M&#x27;</span>)</span><br><span class="line">source = pages_date.find(<span class="string">&#x27;span&#x27;</span>, class_=<span class="string">&#x27;font&#x27;</span>).text.strip().replace(<span class="string">&#x27;来源：&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;发布时间：&quot;</span>, publish_time)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;来源：&quot;</span>, source)</span><br></pre></td></tr></table></figure></div>
<h5 id="提取正文"><a href="#提取正文" class="headerlink" title="提取正文"></a>提取正文</h5><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用id属性查找包含正文内容的div元素</span></span><br><span class="line">pages_content = soup.find(<span class="string">&#x27;div&#x27;</span>, <span class="built_in">id</span>=<span class="string">&#x27;UCAP-CONTENT&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找正文内容中的所有p元素</span></span><br><span class="line">p_tags = pages_content.find_all(<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历所有的p标签，并将它们的文本内容连接起来</span></span><br><span class="line">text = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> p_tag <span class="keyword">in</span> p_tags:</span><br><span class="line">    <span class="comment"># 判断该p标签内是否包含&lt;span&gt;标签</span></span><br><span class="line">    <span class="keyword">if</span> p_tag.find(<span class="string">&#x27;span&#x27;</span>):</span><br><span class="line">        <span class="comment"># 使用extract()方法将该&lt;span&gt;标签从文档中去除</span></span><br><span class="line">        p_tag.find(<span class="string">&#x27;span&#x27;</span>).extract()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将该p标签的文本内容连接到text变量中</span></span><br><span class="line">    text += p_tag.text.strip() + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(text)</span><br></pre></td></tr></table></figure></div>
<h4 id="处理绝对url"><a href="#处理绝对url" class="headerlink" title="处理绝对url"></a>处理绝对url</h4><p>绝对url有主题分类，发文机关，标题，发文字号，成文日期，发布日期,正文</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line">url = <span class="string">&#x27;http://www.gov.cn/zhengce/content/2023-04/12/content_5750986.htm&#x27;</span></span><br><span class="line">UA = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36&#x27;</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;User_Agent&#x27;</span>: UA&#125;</span><br><span class="line"></span><br><span class="line">r = requests.get(url, headers=headers)</span><br><span class="line">r.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(r.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到包含信息的表格标签</span></span><br><span class="line">info_table = soup.find(<span class="string">&#x27;table&#x27;</span>, &#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;bd1&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到每个信息所在的表格行，并提取数据</span></span><br><span class="line">rows = info_table.find_all(<span class="string">&#x27;tr&#x27;</span>)</span><br><span class="line"></span><br><span class="line">topic_category = rows[<span class="number">0</span>].find_all(<span class="string">&#x27;td&#x27;</span>)[<span class="number">3</span>].text.strip()</span><br><span class="line">publishing_organization = rows[<span class="number">1</span>].find_all(<span class="string">&#x27;td&#x27;</span>)[<span class="number">1</span>].text.strip()</span><br><span class="line">title = rows[<span class="number">2</span>].find_all(<span class="string">&#x27;td&#x27;</span>)[<span class="number">1</span>].text.strip()</span><br><span class="line">document_number = rows[<span class="number">3</span>].find_all(<span class="string">&#x27;td&#x27;</span>)[<span class="number">1</span>].text.strip()</span><br><span class="line">written_date = rows[<span class="number">1</span>].find_all(<span class="string">&#x27;td&#x27;</span>)[<span class="number">3</span>].text.strip()</span><br><span class="line">release_date = rows[<span class="number">3</span>].find_all(<span class="string">&#x27;td&#x27;</span>)[<span class="number">3</span>].text.strip()</span><br><span class="line">written_date = datetime.strptime(written_date, <span class="string">&#x27;%Y年%m月%d日&#x27;</span>)</span><br><span class="line">release_date = datetime.strptime(release_date, <span class="string">&#x27;%Y年%m月%d日&#x27;</span>)</span><br><span class="line"><span class="comment"># 打印提取到的数据</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;主题分类：&#x27;</span>, topic_category)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;发文机关：&#x27;</span>, publishing_organization)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;标题：&#x27;</span>, title)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;发文字号：&#x27;</span>, document_number)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;成文日期：&#x27;</span>, written_date)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;发布日期：&#x27;</span>, release_date)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用id属性查找包含正文内容的div元素</span></span><br><span class="line">pages_content = soup.find(<span class="string">&#x27;td&#x27;</span>, <span class="built_in">id</span>=<span class="string">&#x27;UCAP-CONTENT&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找正文内容中的所有p元素</span></span><br><span class="line">p_tags = pages_content.find_all(<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历所有的p标签，并将它们的文本内容连接起来</span></span><br><span class="line">text = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> p_tag <span class="keyword">in</span> p_tags:</span><br><span class="line">    <span class="comment"># 判断该p标签内是否包含&lt;span&gt;标签</span></span><br><span class="line">    <span class="keyword">if</span> p_tag.find(<span class="string">&#x27;span&#x27;</span>):</span><br><span class="line">        <span class="comment"># 使用extract()方法将该&lt;span&gt;标签从文档中去除</span></span><br><span class="line">        p_tag.find(<span class="string">&#x27;span&#x27;</span>).extract()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将该p标签的文本内容连接到text变量中</span></span><br><span class="line">    text += p_tag.text.strip() + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(text)</span><br></pre></td></tr></table></figure></div>
<h3 id="确保数据不重复"><a href="#确保数据不重复" class="headerlink" title="确保数据不重复"></a>确保数据不重复</h3><p>使用pickle模块将已经爬取过的url保存到本地，下次爬取时，先从本地读取已经爬取过的url，然后再进行爬取，这样就可以确保数据不重复了。</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data.pickle&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    visited_urls = pickle.load(f)</span><br><span class="line">    <span class="built_in">print</span>(visited_urls)</span><br></pre></td></tr></table></figure></div>
<h2 id="最终代码"><a href="#最终代码" class="headerlink" title="最终代码"></a>最终代码</h2><div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> pymysql <span class="keyword">import</span> Error</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">crawl_and_process</span>(<span class="params">urls_to_crawl</span>):</span><br><span class="line">    conn = pymysql.connect(host=<span class="string">&#x27;&#x27;</span>, user=<span class="string">&#x27;root&#x27;</span>, password=<span class="string">&#x27;&#x27;</span>, database=<span class="string">&#x27;search&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建游标对象</span></span><br><span class="line">    cursor = conn.cursor()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查询数据库中最大的主键值</span></span><br><span class="line">    cursor.execute(<span class="string">&#x27;SELECT MAX(policy_id) FROM search_policy&#x27;</span>)</span><br><span class="line">    result = cursor.fetchone()</span><br><span class="line">    max_id = result[<span class="number">0</span>] <span class="keyword">if</span> result[<span class="number">0</span>] <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将新数据的主键值设置为查询到的最大主键值加1</span></span><br><span class="line">    new_id = <span class="built_in">int</span>(max_id) + <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="number">23</span>,new_id)</span><br><span class="line">    new_id = <span class="built_in">str</span>(new_id)</span><br><span class="line">    <span class="comment"># 读取已经爬取的URL</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data.pickle&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            visited_urls = pickle.load(f)</span><br><span class="line">            <span class="built_in">print</span>(visited_urls)</span><br><span class="line">    <span class="keyword">except</span> FileNotFoundError:</span><br><span class="line">        visited_urls = <span class="built_in">set</span>() <span class="comment">#实际我生成的是列表</span></span><br><span class="line">    </span><br><span class="line">    data1 =[]</span><br><span class="line">    count1 = <span class="number">0</span></span><br><span class="line">    count2 = <span class="number">0</span></span><br><span class="line">    data2=[]</span><br><span class="line">    sql1 = <span class="string">&#x27;INSERT INTO search_policy (policy_id, policy_title, pub_time, pub_agency, policy_body,policy_grade) VALUES (%s, %s,  %s, %s, %s, %s)&#x27;</span></span><br><span class="line">    sql2 = <span class="string">&#x27;INSERT INTO search_policy (policy_id, policy_title, pub_agency,pub_time,UPDATE_DATE,pub_number, policy_body,policy_grade) VALUES (%s, %s,  %s, %s,  %s, %s, %s, %s)&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls_to_crawl:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 判断URL是否已经被爬取过</span></span><br><span class="line">        <span class="keyword">if</span> url <span class="keyword">in</span> visited_urls:</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 爬取URL并进行数据处理</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;/content/&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> url:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;正在爬取：&#x27;</span>, url)</span><br><span class="line">            data1.append(relativeurl(url,new_id))</span><br><span class="line">            new_id = <span class="built_in">int</span>(new_id) + <span class="number">1</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="number">52</span>,new_id)</span><br><span class="line">            new_id = <span class="built_in">str</span>(new_id)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;正在爬取：&#x27;</span>, url)</span><br><span class="line">            data2.append(absoluteurl(url,new_id))</span><br><span class="line">            new_id = <span class="built_in">int</span>(new_id) + <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            new_id = <span class="built_in">str</span>(new_id)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 将已经爬取的URL添加到visited_urls中</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="number">64</span>)    </span><br><span class="line">        visited_urls.append(url)</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">66</span>,)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(data1) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;enter&#x27;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            cursor.executemany(sql1, data1)</span><br><span class="line">            conn.commit()</span><br><span class="line">        <span class="keyword">except</span> Error <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line">            conn.rollback()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(data2) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;enter&#x27;</span>)</span><br><span class="line">        cursor.executemany(sql2, data2)</span><br><span class="line">        conn.commit()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">74</span>)</span><br><span class="line">    <span class="comment"># 保存visited_urls到pickle文件中</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data.pickle&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        pickle.dump(visited_urls, f)</span><br><span class="line">    cursor.close()</span><br><span class="line">    conn.close() </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_relative_url</span>(<span class="params">url</span>):<span class="comment">#判断是否为相对路径</span></span><br><span class="line">    parsed_url = urlparse(url)</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">not</span> <span class="built_in">bool</span>(parsed_url.netloc)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">relativeurl</span>(<span class="params">url,new_id</span>):</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    UA = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36&#x27;</span></span><br><span class="line">    headers = &#123;<span class="string">&#x27;User_Agent&#x27;</span>: UA&#125;</span><br><span class="line"></span><br><span class="line">    r = requests.get(url, headers=headers)</span><br><span class="line">    r.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line"></span><br><span class="line">    soup = BeautifulSoup(r.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    title_element = soup.find(<span class="string">&#x27;h1&#x27;</span>)</span><br><span class="line">    title = title_element.get_text().strip()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用class属性查找包含发布时间和来源的div元素</span></span><br><span class="line">    pages_date = soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;pages-date&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取发布时间和来源的文本内容</span></span><br><span class="line">    publish_time = pages_date.contents[<span class="number">0</span>].strip()</span><br><span class="line">    <span class="comment"># 将日期字符串转换为datetime类型的数据</span></span><br><span class="line">    publish_time = datetime.strptime(publish_time, <span class="string">&#x27;%Y-%m-%d %H:%M&#x27;</span>)</span><br><span class="line">    source = pages_date.find(<span class="string">&#x27;span&#x27;</span>, class_=<span class="string">&#x27;font&#x27;</span>).text.strip().replace(<span class="string">&#x27;来源：&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用id属性查找包含正文内容的div元素</span></span><br><span class="line">    pages_content = soup.find(<span class="string">&#x27;div&#x27;</span>, <span class="built_in">id</span>=<span class="string">&#x27;UCAP-CONTENT&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 查找正文内容中的所有p元素</span></span><br><span class="line">    p_tags = pages_content.find_all(<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历所有的p标签，并将它们的文本内容连接起来</span></span><br><span class="line">    text = <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> p_tag <span class="keyword">in</span> p_tags:</span><br><span class="line">        <span class="comment"># 判断该p标签内是否包含&lt;span&gt;标签</span></span><br><span class="line">        <span class="keyword">if</span> p_tag.find(<span class="string">&#x27;span&#x27;</span>):</span><br><span class="line">            <span class="comment"># 使用extract()方法将该&lt;span&gt;标签从文档中去除</span></span><br><span class="line">            p_tag.find(<span class="string">&#x27;span&#x27;</span>).extract()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将该p标签的文本内容连接到text变量中</span></span><br><span class="line">        text += p_tag.text.strip() + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line">    data = (new_id,title, publish_time, source, text,<span class="string">&#x27;国家级&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">125</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">absoluteurl</span>(<span class="params">url,new_id</span>):</span><br><span class="line">    UA = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36&#x27;</span></span><br><span class="line">    headers = &#123;<span class="string">&#x27;User_Agent&#x27;</span>: UA&#125;</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;正在爬取：&#x27;</span>, url)</span><br><span class="line">    r = requests.get(url, headers=headers)</span><br><span class="line">    r.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line">    soup = BeautifulSoup(r.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    <span class="comment"># 找到包含信息的表格标签</span></span><br><span class="line">    info_table = soup.find(<span class="string">&#x27;table&#x27;</span>, &#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;bd1&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 找到每个信息所在的表格行，并提取数据</span></span><br><span class="line">    rows = info_table.find_all(<span class="string">&#x27;tr&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    topic_category = rows[<span class="number">0</span>].find_all(<span class="string">&#x27;td&#x27;</span>)[<span class="number">3</span>].text.strip()</span><br><span class="line">    publishing_organization = rows[<span class="number">1</span>].find_all(<span class="string">&#x27;td&#x27;</span>)[<span class="number">1</span>].text.strip()</span><br><span class="line">    title = rows[<span class="number">2</span>].find_all(<span class="string">&#x27;td&#x27;</span>)[<span class="number">1</span>].text.strip()</span><br><span class="line">    document_number = rows[<span class="number">3</span>].find_all(<span class="string">&#x27;td&#x27;</span>)[<span class="number">1</span>].text.strip()</span><br><span class="line">    written_date = rows[<span class="number">1</span>].find_all(<span class="string">&#x27;td&#x27;</span>)[<span class="number">3</span>].text.strip()</span><br><span class="line">    release_date = rows[<span class="number">3</span>].find_all(<span class="string">&#x27;td&#x27;</span>)[<span class="number">3</span>].text.strip()</span><br><span class="line">    written_date = datetime.strptime(written_date, <span class="string">&#x27;%Y年%m月%d日&#x27;</span>)</span><br><span class="line">    release_date = datetime.strptime(release_date, <span class="string">&#x27;%Y年%m月%d日&#x27;</span>)</span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用id属性查找包含正文内容的div元素</span></span><br><span class="line">    pages_content = soup.find(<span class="string">&#x27;td&#x27;</span>, <span class="built_in">id</span>=<span class="string">&#x27;UCAP-CONTENT&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查找正文内容中的所有p元素</span></span><br><span class="line">    p_tags = pages_content.find_all(<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历所有的p标签，并将它们的文本内容连接起来</span></span><br><span class="line">    text = <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> p_tag <span class="keyword">in</span> p_tags:</span><br><span class="line">        <span class="comment"># 判断该p标签内是否包含&lt;span&gt;标签</span></span><br><span class="line">        <span class="keyword">if</span> p_tag.find(<span class="string">&#x27;span&#x27;</span>):</span><br><span class="line">            <span class="comment"># 使用extract()方法将该&lt;span&gt;标签从文档中去除</span></span><br><span class="line">            p_tag.find(<span class="string">&#x27;span&#x27;</span>).extract()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将该p标签的文本内容连接到text变量中</span></span><br><span class="line">        text += p_tag.text.strip() + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">    </span><br><span class="line">    data = (new_id,title,publishing_organization,written_date,release_date,document_number,text,<span class="string">&#x27;国家级&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">UA = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36&#x27;</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;User_Agent&#x27;</span>: UA&#125;</span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">83</span>):  <span class="comment"># 假设要爬取前100页</span></span><br><span class="line">    cn = <span class="string">f&#x27;http://sousuo.gov.cn/column/30469/<span class="subst">&#123;page&#125;</span>.htm&#x27;</span></span><br><span class="line">    <span class="comment"># 爬取该页的数据</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(cn, headers=headers)</span><br><span class="line">        r.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line"></span><br><span class="line">        soup = BeautifulSoup(r.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">        <span class="comment">#获取该页的所有政策链接</span></span><br><span class="line">        links = soup.find_all(href=re.<span class="built_in">compile</span>(<span class="string">&#x27;content&#x27;</span>))</span><br><span class="line">        urls = []</span><br><span class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">            </span><br><span class="line">            url = link.get(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">            urls.append(<span class="built_in">str</span>(url))</span><br><span class="line">        <span class="built_in">print</span>(urls)</span><br><span class="line">        crawl_and_process(urls)</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 关闭游标和连接</span></span><br><span class="line">           </span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br></pre></td></tr></table></figure></div>
		</div>

		
		<div class="post-copyright-info w-full my-8 px-2 sm:px-6 md:px-8">
			<div class="article-copyright-info-container">
    <ul>
        <li><strong>Title:</strong> 爬虫</li>
        <li><strong>Author:</strong> Ikko</li>
        <li><strong>Created at
                :</strong> 2023-04-19 12:58:02</li>
        
            <li>
                <strong>Updated at
                    :</strong> 2023-05-22 14:16:01
            </li>
        
        <li>
            <strong>Link:</strong> http://ikko-debug.github.io/2023/04/19/爬虫/
        </li>
        <li>
            <strong>
                License:
            </strong>
            

            
                This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0">CC BY-NC-SA 4.0</a>.
            
        </li>
    </ul>
</div>

		</div>
		

		

		

		
		<div class="article-nav my-8 flex justify-between items-center px-2 sm:px-6 md:px-8">
			
			<div class="article-prev border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="prev" rel="prev" href="/2023/06/03/django%E5%BC%80%E5%8F%91api/">
					<span class="left arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-left"></i>
					</span>
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item">django开发api</span>
						<span class="post-nav-item">Prev posts</span>
					</span>
				</a>
			</div>
			
			
			<div class="article-next border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="next" rel="next" href="/2023/04/14/django%E9%83%A8%E7%BD%B2%E4%B8%8A%E4%BA%91/">
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item">django部署上云</span>
						<span class="post-nav-item">Next posts</span>
					</span>
					<span class="right arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-right"></i>
					</span>
				</a>
			</div>
			
		</div>
		


		
		<div class="comment-container px-2 sm:px-6 md:px-8 pb-8">
			<div class="comments-container mt-10 w-full ">
    <div id="comment-anchor" class="w-full h-2.5"></div>
    <div class="comment-area-title w-full my-1.5 md:my-2.5 text-xl md:text-3xl font-bold">
        Comments
    </div>
    

        
            
    <div id="gitalk-container"></div>
    <script data-swup-reload-script
            src="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js"></script>
    <script data-swup-reload-script>

        function loadGitalk() {
            let __gitalk__pathname = decodeURI(location.pathname);
            const __gitalk__pathnameLength = __gitalk__pathname.length;
            const __gitalk__pathnameMaxLength = 50;
            if (__gitalk__pathnameLength > __gitalk__pathnameMaxLength) {
                __gitalk__pathname = __gitalk__pathname.substring(0, __gitalk__pathnameMaxLength - 3) + '...';
            }

            try {
                Gitalk && new Gitalk({
                    clientID: '55ccec7ba873a504625f',
                    clientSecret: '5a44aa297b4124ddb3e9a8bb19842a6c066273e6',
                    repo: 'gittalk',
                    owner: 'ikko-debug',
                    admin: ['ikko-debug'],
                    id: __gitalk__pathname,
                    language: 'en',
                    proxy: 'https://github.com/login/oauth/access_token'
                }).render('gitalk-container');

            } catch (e) {
                window.Gitalk = null;
            }
        }

        if ('true') {
            const loadGitalkTimeout = setTimeout(() => {
                loadGitalk();
                clearTimeout(loadGitalkTimeout);
            }, 1000);
        } else {
            window.addEventListener('DOMContentLoaded', loadGitalk);
        }
    </script>



        
    
</div>

		</div>
		
	</div>

	
	<div class="toc-content-container">
		<div class="post-toc-wrap">
	<div class="post-toc">
		<div class="toc-title">On this page</div>
		<div class="page-title">爬虫</div>
		<ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E4%BB%A3%E7%A0%81"><span class="nav-text">初始代码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%AA%E4%BA%BA%E7%90%86%E8%A7%A3"><span class="nav-text">个人理解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E4%BF%AE%E6%94%B9"><span class="nav-text">代码修改</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#url%E4%BF%AE%E6%94%B9"><span class="nav-text">url修改</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9%E6%88%90%E5%8A%9F%E5%90%8E%E5%8F%91%E7%8E%B0%EF%BC%8C%E7%BB%9D%E5%AF%B9url%E5%92%8C%E7%9B%B8%E5%AF%B9url%E5%AF%B9%E5%BA%94%E7%9A%84%E9%A1%B5%E9%9D%A2%E7%BB%93%E6%9E%84%E6%98%AF%E4%B8%8D%E5%90%8C%E7%9A%84"><span class="nav-text">修改成功后发现，绝对url和相对url对应的页面结构是不同的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A1%AE%E4%BF%9D%E6%95%B0%E6%8D%AE%E4%B8%8D%E9%87%8D%E5%A4%8D"><span class="nav-text">确保数据不重复</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%80%E7%BB%88%E4%BB%A3%E7%A0%81"><span class="nav-text">最终代码</span></a></li></ol>

	</div>
</div>
	</div>
	
</div>
			</div>

			
		</div>

		<div class="main-content-footer">
			<footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
        <div class="text-center">
            &copy;
            
              <span>2022</span>
              -
            
            2025&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">Ikko</a>
            
                
                <p class="post-count space-x-0.5">
                    <span>
                        23 posts in total
                    </span>
                    
                        <span>
                            38.5k words in total
                        </span>
                    
                </p>
            
        </div>
        
            <script data-swup-reload-script src="https://cn.vercount.one/js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">VISITOR COUNT</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">TOTAL PAGE VIEWS</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span>
            <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.8.2</a></span>
        </div>
        
        
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
		</div>
	</div>

	
	<div class="post-tools">
		<div class="post-tools-container">
	<ul class="article-tools-list">
		<!-- TOC aside toggle -->
		
		<li class="right-bottom-tools page-aside-toggle">
			<i class="fa-regular fa-outdent"></i>
		</li>
		

		<!-- go comment -->
		
		<li class="go-comment">
			<i class="fa-regular fa-comments"></i>
		</li>
		
	</ul>
</div>
	</div>
	

	<div class="right-side-tools-container">
		<div class="side-tools-container">
	<ul class="hidden-tools-list">
		<li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-plus"></i>
		</li>

		<li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-minus"></i>
		</li>

		<li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
			<i class="fa-regular fa-moon"></i>
		</li>

		<!-- rss -->
		

		

		<li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
			<i class="fa-regular fa-arrow-down"></i>
		</li>
	</ul>

	<ul class="visible-tools-list">
		<li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
			<i class="fa-regular fa-cog fa-spin"></i>
		</li>
		
		<li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
			<i class="arrow-up fas fa-arrow-up"></i>
			<span class="percent"></span>
		</li>
		
		
	</ul>
</div>
	</div>

	<div class="image-viewer-container">
	<img src="">
</div>

	
	<div class="search-pop-overlay">
	<div class="popup search-popup">
		<div class="search-header">
			<span class="search-input-field-pre">
				<i class="fa-solid fa-keyboard"></i>
			</span>
			<div class="search-input-container">
				<input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="Search..." spellcheck="false" type="search" class="search-input">
			</div>
			<span class="popup-btn-close">
				<i class="fa-solid fa-times"></i>
			</span>
		</div>
		<div id="search-result">
			<div id="no-result">
				<i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i>
			</div>
		</div>
	</div>
</div>
	

</main>


<script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/Swup.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupSlideTheme.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupScriptsPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupProgressPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupScrollPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupPreloadPlugin.min.js" ></script>
<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
            new SwupPreloadPlugin(),
        ],
        containers: ["#swup"],
    });
</script>




	<script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/imageViewer.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/utils.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/main.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/navbarShrink.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/scrollTopBottom.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/lightDarkSwitch.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/categoryList.js" ></script>


    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/localSearch.js" ></script>



    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/codeBlock.js" ></script>



    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/lazyload.js" ></script>



    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/runtime.js" ></script>
    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/odometer.min.js" ></script>
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/assets/odometer-theme-minimal.css">



  <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/Typed.min.js" ></script>
  <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/plugins/typed.js" ></script>





    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/minimasonry.min.js" ></script>
    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/plugins/masonry.js" ></script>



    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/anime.min.js" ></script>




    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/tocToggle.js" data-swup-reload-script></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/toc.js" data-swup-reload-script></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/plugins/tabs.js" data-swup-reload-script></script>


<script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/moment-with-locales.min.js" data-swup-reload-script></script>
<script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/essays.js" data-swup-reload-script></script>




	
</body>

</html>